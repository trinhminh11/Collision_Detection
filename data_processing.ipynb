{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ac0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e65ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FRAMES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3003d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_196937/619700777.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['time_of_event'].replace({float('nan'): None}, inplace=True)\n",
      "/tmp/ipykernel_196937/619700777.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['time_of_alert'].replace({float('nan'): None}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.rename(columns={'target': 'label'}, inplace=True)\n",
    "\n",
    "df['time_of_event'].replace({float('nan'): None}, inplace=True)\n",
    "\n",
    "df['time_of_alert'].replace({float('nan'): None}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "170571b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df: pd.DataFrame\n",
    "val_df: pd.DataFrame\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ef3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id'] = train_df['id'].astype(str).str.zfill(5)\n",
    "val_df['id'] = val_df['id'].astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b744b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['vid_path'] = \"data/\" + train_df['id'] + '.mp4'\n",
    "val_df['vid_path'] = \"data/\" + val_df['id'] + '.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d17eb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(299),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, n_frames = 16, transform: Callable= lambda x: x):\n",
    "        self.item_id = df['id'].astype(str).str.zfill(5).tolist()\n",
    "        self.vid_path = df['vid_path'].tolist()\n",
    "\n",
    "        self.time_of_event = df['time_of_event'].tolist()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.n_frames = n_frames\n",
    "\n",
    "\n",
    "    def extract_frames(self, idx: int):\n",
    "        path = self.vid_path[idx]\n",
    "\n",
    "        cap = cv2.VideoCapture(path)\n",
    "\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        duration = frame_count / fps\n",
    "        \n",
    "        time = self.time_of_event[idx]\n",
    "\n",
    "        if time and time != float('nan'):\n",
    "            sample_idx = np.linspace(0, frame_count-1, self.n_frames, dtype=int)\n",
    "            f = int(round(time * fps))\n",
    "            k = np.searchsorted(sample_idx, f, side='right') - 1\n",
    "        else:\n",
    "            k = None\n",
    "\n",
    "        \n",
    "        step = max(frame_count // self.n_frames, 1)\n",
    "        frames = []\n",
    "\n",
    "        for i in range(self.n_frames):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            frame = Image.fromarray(frame)\n",
    "            frame = self.transform(frame)\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        return torch.stack(frames), k\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vid_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_id = self.item_id[idx]\n",
    "        frames, k = self.extract_frames(idx)\n",
    "\n",
    "        return item_id, frames, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a5458d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(train_df, n_frames=N_FRAMES, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44328dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = CustomDataset(val_df, n_frames=N_FRAMES, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"train_tensor\", exist_ok=True)\n",
    "os.makedirs(\"val_tensor\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d27aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [26:55<00:00,  1.35s/it]\n",
      "100%|██████████| 300/300 [06:39<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "### Train\n",
    "\n",
    "train_k = []\n",
    "for item_id, frames, k in tqdm(train_ds):\n",
    "    torch.save(frames, os.path.join('train_tensor', item_id + '.pt'))\n",
    "    if k is None:\n",
    "        k = -1\n",
    "    train_k.append(k)\n",
    "\n",
    "### Validation\n",
    "val_k = []\n",
    "for item_id, frames, k in tqdm(val_ds):\n",
    "    torch.save(frames, os.path.join('val_tensor', item_id + '.pt'))\n",
    "    if k is None:\n",
    "        k = -1\n",
    "    val_k.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ae7b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['event_frame'] = train_k\n",
    "val_df['event_frame'] = val_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7af1efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sort_values(by='id', inplace=True)\n",
    "val_df.sort_values(by='id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1fd95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tensor_path'] = \"train_tensor/\" + train_df['id'] + '.pt'\n",
    "val_df['tensor_path'] = \"val_tensor/\" + val_df['id'] + '.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1535a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.csv', index=False)\n",
    "val_df.to_csv('val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bbe965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
