{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4188ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb13b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_feats = True      # False if you want to use the cached features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30979a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4df02bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fool/anaconda3/envs/PyTorch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fool/anaconda3/envs/PyTorch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_model: models.inception.Inception3 = models.inception_v3(pretrained=True).to(device)\n",
    "backbone_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd71f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = backbone_model.fc.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe32de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "val_df = pd.read_csv('val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6ce436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time_of_event</th>\n",
       "      <th>time_of_alert</th>\n",
       "      <th>label</th>\n",
       "      <th>vid_path</th>\n",
       "      <th>event_frame</th>\n",
       "      <th>tensor_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.760</td>\n",
       "      <td>19.136</td>\n",
       "      <td>1</td>\n",
       "      <td>data/00000.mp4</td>\n",
       "      <td>7</td>\n",
       "      <td>train_tensor/00000.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>19.367</td>\n",
       "      <td>19.167</td>\n",
       "      <td>1</td>\n",
       "      <td>data/00004.mp4</td>\n",
       "      <td>7</td>\n",
       "      <td>train_tensor/00004.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>20.874</td>\n",
       "      <td>20.809</td>\n",
       "      <td>1</td>\n",
       "      <td>data/00005.mp4</td>\n",
       "      <td>7</td>\n",
       "      <td>train_tensor/00005.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>19.233</td>\n",
       "      <td>17.133</td>\n",
       "      <td>1</td>\n",
       "      <td>data/00006.mp4</td>\n",
       "      <td>7</td>\n",
       "      <td>train_tensor/00006.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>21.200</td>\n",
       "      <td>19.500</td>\n",
       "      <td>1</td>\n",
       "      <td>data/00007.mp4</td>\n",
       "      <td>7</td>\n",
       "      <td>train_tensor/00007.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>2132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/02132.mp4</td>\n",
       "      <td>-1</td>\n",
       "      <td>train_tensor/02132.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/02133.mp4</td>\n",
       "      <td>-1</td>\n",
       "      <td>train_tensor/02133.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/02134.mp4</td>\n",
       "      <td>-1</td>\n",
       "      <td>train_tensor/02134.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/02136.mp4</td>\n",
       "      <td>-1</td>\n",
       "      <td>train_tensor/02136.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/02137.mp4</td>\n",
       "      <td>-1</td>\n",
       "      <td>train_tensor/02137.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  time_of_event  time_of_alert  label        vid_path  event_frame  \\\n",
       "0        0         20.760         19.136      1  data/00000.mp4            7   \n",
       "1        4         19.367         19.167      1  data/00004.mp4            7   \n",
       "2        5         20.874         20.809      1  data/00005.mp4            7   \n",
       "3        6         19.233         17.133      1  data/00006.mp4            7   \n",
       "4        7         21.200         19.500      1  data/00007.mp4            7   \n",
       "...    ...            ...            ...    ...             ...          ...   \n",
       "1195  2132            NaN            NaN      0  data/02132.mp4           -1   \n",
       "1196  2133            NaN            NaN      0  data/02133.mp4           -1   \n",
       "1197  2134            NaN            NaN      0  data/02134.mp4           -1   \n",
       "1198  2136            NaN            NaN      0  data/02136.mp4           -1   \n",
       "1199  2137            NaN            NaN      0  data/02137.mp4           -1   \n",
       "\n",
       "                tensor_path  \n",
       "0     train_tensor/00000.pt  \n",
       "1     train_tensor/00004.pt  \n",
       "2     train_tensor/00005.pt  \n",
       "3     train_tensor/00006.pt  \n",
       "4     train_tensor/00007.pt  \n",
       "...                     ...  \n",
       "1195  train_tensor/02132.pt  \n",
       "1196  train_tensor/02133.pt  \n",
       "1197  train_tensor/02134.pt  \n",
       "1198  train_tensor/02136.pt  \n",
       "1199  train_tensor/02137.pt  \n",
       "\n",
       "[1200 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad287b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.X = df['tensor_path'].tolist()\n",
    "        self.y = df['label'].tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        tensor_path = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        # Load the Tensor\n",
    "        tensor: torch.Tensor = torch.load(tensor_path)\n",
    "\n",
    "        return tensor, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0360534",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(train_df)\n",
    "val_ds = CustomDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f99a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model: torch.nn.Module, ds: Dataset, device: str = 'cuda') -> np.ndarray:\n",
    "    features = []\n",
    "\n",
    "    for X, y in tqdm(ds):\n",
    "        X = X.to(device)\n",
    "        feat: torch.Tensor = model(X)\n",
    "        feat = feat.detach().cpu().numpy()\n",
    "\n",
    "        features.append(feat)\n",
    "\n",
    "    return np.stack(features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c8e1b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_feats:\n",
    "    train_feats = get_features(backbone_model, train_ds)\n",
    "    np.save('train_feats.npy', train_feats)\n",
    "\n",
    "if rerun_feats:\n",
    "    val_feats = get_features(backbone_model, val_ds)\n",
    "    np.save('val_feats.npy', val_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da8f3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats: np.ndarray = np.load('train_feats.npy')\n",
    "val_feats: np.ndarray = np.load('val_feats.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "786ab74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train: np.ndarray = train_df['label'].values\n",
    "y_val: np.ndarray = val_df['label'].values\n",
    "frame_train: np.ndarray = train_df['event_frame'].values\n",
    "frame_val: np.ndarray = val_df['event_frame'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83d6c377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200, 16, 1000), (300, 16, 1000))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.shape, val_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db4c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_processer(feats: np.ndarray) -> np.ndarray:\n",
    "    return feats.reshape(feats.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eed839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processer = reshape_processer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bd0e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        feats = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        return feats, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef502d5",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = torch.nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.device = device\n",
    "    \n",
    "    def to(self, device: str):\n",
    "        self.device = device\n",
    "        return super().to(device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, ds: Dataset, epochs: int = 10, batch_size: int = 32, lr = 0.001):\n",
    "        self.train()\n",
    "        dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            for X_batch, y_batch in dl:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device).float()\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self(X_batch)\n",
    "                loss = criterion(y_pred.squeeze(), y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_proba(self, ds: Dataset) -> np.ndarray:\n",
    "        self.eval()\n",
    "        dl = DataLoader(ds, batch_size=32, shuffle=False)\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for X_batch, _ in dl:\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_pred = self(X_batch)\n",
    "            preds.append(y_pred.squeeze().cpu().numpy())\n",
    "        \n",
    "        return np.concatenate(preds, axis=0)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluation(self, ds: Dataset, threshold=0.5) -> np.ndarray:\n",
    "        self.eval()\n",
    "        dl = DataLoader(ds, batch_size=32, shuffle=False)\n",
    "\n",
    "        correct = 0\n",
    "        n = len(ds)\n",
    "\n",
    "        for X_batch, y_batch in dl:\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            y_pred = self(X_batch)\n",
    "\n",
    "            y_pred = (y_pred.squeeze() > threshold).int()\n",
    "            correct += (y_pred == y_batch).sum().item()\n",
    "        \n",
    "        return correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1385bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(processer(train_feats), y_train)\n",
    "val_ds = CustomDataset(processer(val_feats), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b693d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = train_ds[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da52e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: BinaryClassifier = BinaryClassifier(input_dim=feat_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aecfe539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 19.57it/s]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7612f602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC: 0.7261333333333333\n"
     ]
    }
   ],
   "source": [
    "val_score = model.predict_proba(val_ds)\n",
    "print(\"Validation ROC-AUC:\", roc_auc_score(y_val, val_score))        # 0.9: Excellent, 0.8: Good, 0.7: Fair, 0.6: Poor, 0.5: Fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5f0661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresh = roc_curve(y_val, val_score)\n",
    "j_scores = tpr - fpr\n",
    "best_idx = np.argmax(j_scores)\n",
    "best_threshold = thresh[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98d58bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6433333333333333, 0.67)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluation(val_ds), model.evaluation(val_ds, best_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0dd4a",
   "metadata": {},
   "source": [
    "# TIMESTAMP PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79271b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeStampModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "        self.device = device\n",
    "    \n",
    "    def to(self, device: str):\n",
    "        self.device = device\n",
    "        return super().to(device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, ds: Dataset, epochs: int = 10, batch_size: int = 32, lr = 0.001):\n",
    "        self.train()\n",
    "        dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            for X_batch, y_batch in dl:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluation(self, ds: Dataset) -> np.ndarray:\n",
    "        self.eval()\n",
    "        dl = DataLoader(ds, batch_size=32, shuffle=False)\n",
    "\n",
    "        correct = 0\n",
    "        n = len(ds)\n",
    "\n",
    "        for X_batch, y_batch in dl:\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            y_pred = self(X_batch)\n",
    "\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            correct += (y_pred == y_batch).sum().item()\n",
    "        \n",
    "        return correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b162d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.where(frame_train != -1)[0]\n",
    "val_indices = np.where(frame_val != -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b7229fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(processer(train_feats[train_indices]), frame_train[train_indices])\n",
    "val_ds = CustomDataset(processer(val_feats[val_indices]), frame_val[val_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adadc971",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_model = TimeStampModel(input_dim=feat_dim, output_dim=16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68bfd51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 40.45it/s]\n"
     ]
    }
   ],
   "source": [
    "timestamp_model.fit(train_ds, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0915c527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_model.evaluation(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b701c566",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fffa134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollisionDetection:\n",
    "    def __init__(self, backbone_model: torch.nn.Module, detector_model: BinaryClassifier, timestamp_model: TimeStampModel, transform: Callable, threshold: float = 0.5):\n",
    "        self.backbone_model = backbone_model\n",
    "        self.detector_model = detector_model\n",
    "        self.timestamp_model = timestamp_model\n",
    "        self.transform = transform\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.n_frames = 16\n",
    "\n",
    "    def extract_frames(self, path: int):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        duration = frame_count / fps\n",
    "        \n",
    "        \n",
    "        step = max(frame_count // self.n_frames, 1)\n",
    "        frames = []\n",
    "\n",
    "        for i in range(self.n_frames):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            frame = Image.fromarray(frame)\n",
    "            frame = self.transform(frame)\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        return torch.stack(frames), duration\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def infer_one_video(self, video_path: str):\n",
    "        frames, duration = self.extract_frames(video_path)\n",
    "        frames = frames.to(device)\n",
    "\n",
    "        feats: torch.Tensor = self.backbone_model(frames)\n",
    "\n",
    "        feats = feats.reshape(-1)        \n",
    "\n",
    "        proba = self.detector_model(feats)\n",
    "\n",
    "        if proba > self.threshold:\n",
    "            timestamp_pred = self.timestamp_model(feats)\n",
    "            timestamp_pred = torch.argmax(timestamp_pred, dim=0).cpu().numpy()\n",
    "\n",
    "            start = timestamp_pred * duration / self.n_frames\n",
    "            end   = (timestamp_pred + 1) * duration / self.n_frames\n",
    "\n",
    "            return start, end\n",
    "        \n",
    "        return -1, -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e93054cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "993049b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = CollisionDetection(\n",
    "    backbone_model=backbone_model,\n",
    "    detector_model=model,\n",
    "    timestamp_model=timestamp_model,\n",
    "    transform=tfm,\n",
    "    threshold=best_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c852112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.54375, 20.05)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.infer_one_video(\"data/00003.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b50589",
   "metadata": {},
   "outputs": [],
   "source": [
    "qsort = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
